{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e124ee83-9fc0-418a-97b7-ae611e459747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.circuit.library import ZFeatureMap, ZZFeatureMap\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_algorithms.optimizers import COBYLA, SPSA, L_BFGS_B, ADAM\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "\n",
    "algorithm_globals.random_seed = 12345\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59fa56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================================================================\n",
    "import seaborn as sns\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import string\n",
    "\n",
    "#===================================================================================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import*\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "#==================================================================================================================================\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "#===================================================================================================================================\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import random\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d7fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_aer import Aer\n",
    "\n",
    "simulator = Aer.get_backend('aer_simulator')\n",
    "simulator.set_options(device='GPU', blocking_qubits=23, blocking_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da710be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now define a two qubit unitary as defined in [3]\n",
    "def conv_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(np.pi / 2, 0)\n",
    "    return target\n",
    "\n",
    "\n",
    "# Let's draw this circuit and see what it looks like\n",
    "params = ParameterVector(\"θ\", length=3)\n",
    "circuit = conv_circuit(params)\n",
    "circuit.draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e1190-731f-48db-91fa-ddbc448bbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(num_qubits, param_prefix):\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Convolutional Layer\")\n",
    "    qubits = list(range(num_qubits))\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=num_qubits * 3)\n",
    "    for q1, q2 in zip(qubits[0::2], qubits[1::2]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : (param_index + 3)]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "    for q1, q2 in zip(qubits[1::2], qubits[2::2] + [0]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : (param_index + 3)]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    qc_inst = qc.to_instruction()\n",
    "\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qc.append(qc_inst, qubits)\n",
    "    return qc\n",
    "\n",
    "\n",
    "circuit = conv_layer(4, \"θ\")\n",
    "circuit.decompose().draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771922e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "params = ParameterVector(\"θ\", length=3)\n",
    "circuit = pool_circuit(params)\n",
    "circuit.draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9649b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_layer(sources, sinks, param_prefix):\n",
    "    num_qubits = len(sources) + len(sinks)\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Pooling Layer\")\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=num_qubits // 2 * 3)\n",
    "    for source, sink in zip(sources, sinks):\n",
    "        qc = qc.compose(pool_circuit(params[param_index : (param_index + 3)]), [source, sink])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    qc_inst = qc.to_instruction()\n",
    "\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qc.append(qc_inst, range(num_qubits))\n",
    "    return qc\n",
    "\n",
    "\n",
    "sources = [0, 1]\n",
    "sinks = [2, 3]\n",
    "circuit = pool_layer(sources, sinks, \"θ\")\n",
    "circuit.decompose().draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3e8c4-d8b5-4713-b228-eb7d6a28f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================= Parâmetros dos experimentos============================================================================\n",
    "filename = \"anomalies.csv\"\n",
    "path = os.path.join(os.getcwd(), 'input_data_embraer')\n",
    "df = pd.read_csv(os.path.join(path, filename), low_memory=False)\n",
    "df.Anomaly.value_counts()\n",
    "Anomaly =[['AF',]]\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1_Score']\n",
    "savefig = False # Salvar Figuras\n",
    "random_state = 45\n",
    "numbers_features = 2 # Numeros de Features para serem selecionadas\n",
    "batch_size = 400 # Tamanho dos batchs para treino\n",
    "qLayers = 1  # Número de camadas do circuito quântico\n",
    "perc_F_NF = 0.3  # Relação de falha com não falha\n",
    "res_C = []\n",
    "res_Q  = []\n",
    "result_kernel = []\n",
    "i = 0\n",
    "#=================================================================================================================================================================\n",
    "\n",
    "print(df.shape)\n",
    "df_nf = df[df.Anomaly=='NF']\n",
    "df_f = df[df.Anomaly !='NF']\n",
    "\n",
    "\n",
    "num_NF = (df_f['Anomaly'].value_counts()[Anomaly[i]] - perc_F_NF*df_f['Anomaly'].value_counts()[Anomaly[i]])/perc_F_NF\n",
    "num_NF = int(round(num_NF, 0))\n",
    "#print(num_NF)\n",
    "\n",
    "df_nf = df[df.Anomaly=='NF'].sample(num_NF, replace=True ,random_state=random_state) # SELECIONANDO 300 SAMPLES DE CASOS DE NÃO FALHA\n",
    "df = pd.concat((df_nf, df_f), axis=0).reset_index(drop=True)\n",
    "\n",
    "df = df.drop(columns=['_time'])\n",
    "\n",
    "\n",
    "#df= df[(df['Anomaly'] == 'NF') | (df['Anomaly'] == Anomaly[0][0])| (df['Anomaly'] == Anomaly[0][1])| (df['Anomaly'] == Anomaly[0][2])| (df['Anomaly'] == Anomaly[0][3])| (df['Anomaly'] == Anomaly[0][4])]\n",
    "#df= df[(df['Anomaly'] == 'NF') | (df['Anomaly'] == Anomaly[0][0])]\n",
    "df['Anomaly'].value_counts().plot.pie(autopct = '%.2f%%', title = 'Anomalys Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439ee59-6397-4b8a-b754-76360cdb1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(len(df))\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 0:\n",
    "        y[i] = 1\n",
    "    elif y[i] == 1:\n",
    "        y[i] = -1\n",
    "        \n",
    "        \n",
    "df.Anomaly.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726318a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "def feature_selectionRFE(max_iter,data,X, y, numbers_features):\n",
    "    std = StandardScaler()\n",
    "    X = std.fit_transform(X)\n",
    "    model = LogisticRegression(max_iter=max_iter)\n",
    "    rfe = RFE(model,n_features_to_select=numbers_features)\n",
    "    fit = rfe.fit(X,y)\n",
    "    cols = fit.get_support(indices=True)\n",
    "    features = data.iloc[:,cols]\n",
    "    \n",
    "    return features, cols\n",
    "\n",
    "def feature_selectionKBest(X, y, numbers_features):\n",
    "    std = StandardScaler()\n",
    "    X = std.fit_transform(X)\n",
    "    kbest = SelectKBest(score_func=f_classif, k=numbers_features)\n",
    "    fit = kbest.fit(X,y)\n",
    "    X_selected = kbest.fit_transform(X, y)\n",
    "\n",
    "    return X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353a0c4-5a30-4d1d-ba70-292fb156b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#X_RFE = feature_selectionRFE(max_iter=500,data = df, X=X, y=y, numbers_features=numbers_features)\n",
    "#X = X_RFE[0] # Redução de features\n",
    "#X_Best = feature_selectionKBest(X=X, y=y, numbers_features=numbers_features)\n",
    "#X =X_Best[0]\n",
    "\n",
    "# Apply undersampling using RandomUnderSampler\n",
    "#undersampler = RandomUnderSampler(sampling_strategy='not minority', random_state=42)\n",
    "#X, y = undersampler.fit_resample(X, y)\n",
    "#smote = smote = SMOTE(random_state=42)\n",
    "#X, y = smote.fit_resample(X, y)\n",
    "\n",
    "\n",
    "test_size = 0.20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state= random_state)\n",
    "\n",
    "print(\"Quantidade de DADOS DE FALHA/NAOFALHA\", df.Anomaly.value_counts())\n",
    "print(\"\\n\")\n",
    "print(\"Quantidade de DADOS TOTAL\", df.Anomaly.shape[0])\n",
    "print(f\"Porcentagem de DADOS PARA TREINO {(1-test_size)*100}%\")\n",
    "print(f\"Porcentagem de DADOS PARA TESTE {(test_size)*100}%\")\n",
    "print(f\"FORMATO X_train: {X_train.shape}\\nFORMATO X_test: {X_test.shape}\\nFormato y_train: {y_train.shape}\\nFormato y_test: {y_test.shape}\")\n",
    "# Update n_features\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# Now use X_selected instead of X in your quantum circuit\n",
    "\n",
    "#print(\"Quantidade de FEATURES:\", n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f363f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalling\n",
    "std = StandardScaler()\n",
    "X_train_prep = pd.DataFrame(std.fit_transform(X_train))\n",
    "X_test_prep = pd.DataFrame(std.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59154c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = ZFeatureMap(n_features)\n",
    "feature_map.decompose().draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b53d1300-6173-4323-9afb-1766b2d47343",
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = QuantumCircuit(n_features, name=\"Ansatz\")\n",
    "\n",
    "# First Convolutional Layer\n",
    "ansatz.compose(conv_layer(n_features, \"c1\"), list(range(n_features)), inplace=True)\n",
    "\n",
    "# First Pooling Layer\n",
    "n_qubits_after_pool1 = int(n_features / 2)  # This will be 27\n",
    "ansatz.compose(pool_layer(list(range(n_qubits_after_pool1)), list(range(n_qubits_after_pool1, n_features)), \"p1\"), list(range(n_features)), inplace=True)\n",
    "\n",
    "# Second Convolutional Layer\n",
    "n_qubits_conv2 = n_features - n_qubits_after_pool1  # This will be 28\n",
    "ansatz.compose(conv_layer(n_qubits_conv2, \"c2\"), list(range(n_qubits_after_pool1, n_features)), inplace=True)\n",
    "\n",
    "# Second Pooling Layer\n",
    "n_qubits_after_pool2 = int(n_qubits_conv2 / 2)  # This will be 14\n",
    "ansatz.compose(pool_layer(list(range(n_qubits_after_pool2)), list(range(n_qubits_after_pool2, n_qubits_conv2)), \"p2\"), list(range(n_qubits_after_pool1, n_features)), inplace=True)\n",
    "\n",
    "# Third Convolutional Layer\n",
    "n_qubits_conv3 = int(n_qubits_conv2 - n_qubits_after_pool2)  # This will be 14\n",
    "ansatz.compose(conv_layer(n_qubits_conv3, \"c3\"), list(range(n_features - n_qubits_conv3, n_features)), inplace=True)\n",
    "\n",
    "# Third Pooling Layer\n",
    "n_qubits_after_pool3 = n_qubits_conv3 // 2  # This will be 7\n",
    "ansatz.compose(pool_layer(list(range(n_qubits_after_pool3)), list(range(n_qubits_after_pool3, n_qubits_conv3)), \"p3\"), list(range(n_features - n_qubits_conv3, n_features)), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b30c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combining the feature map and ansatz\n",
    "circuit = QuantumCircuit(n_features)\n",
    "circuit.compose(feature_map, range(n_features), inplace=True)\n",
    "circuit.compose(ansatz, range(n_features), inplace=True)\n",
    "\n",
    "n = n_features -1\n",
    "\n",
    "observable = SparsePauliOp.from_list([(\"Z\" + \"I\" * n, 1)])\n",
    "\n",
    "# we decompose the circuit for the QNN to avoid additional data copying\n",
    "qnn = EstimatorQNN(\n",
    "    circuit=circuit.decompose(),\n",
    "    observables=observable,\n",
    "    input_params=feature_map.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit.draw(\"mpl\", style=\"clifford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef6d04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3306c8e4-b51e-4811-a435-b4be6fb7f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NeuralNetworkClassifier(\n",
    "    qnn,\n",
    "    optimizer=COBYLA(maxiter=2000),  # Set max iterations here\n",
    "    #optimizer=L_BFGS_B(maxiter=50),\n",
    "    callback=callback_graph,\n",
    "    #initial_point=initial_point,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(X_train_prep)\n",
    "y = np.asarray(y_train)\n",
    "\n",
    "objective_func_vals = []\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "classifier.fit(x, y)\n",
    "\n",
    "# score classifier\n",
    "print(f\"Accuracy from the train data : {np.round(100 * classifier.score(x, y), 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479df6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_prep)\n",
    "y_true = np.asarray(y_test)\n",
    "average ='micro'\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame({\"Accuracy\": round(accuracy_score(y_true, y_pred)*100,3),\"Precision\": round(precision_score(y_true, y_pred, average=average)*100,3),\"Recall\": round(recall_score(y_true, y_pred, average=average)*100,3),\"F1_Score\": round(f1_score(y_true, y_pred,average=average)*100,3),}, index = range(4)).head(1)\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458a11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum-maintance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
